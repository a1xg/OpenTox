## OpenTox

Проект OpenTox задумывался, как Android приложение написанное с помощью [Kivy framework](https://github.com/kivy/kivy) для python, выполняющее 
распознавание этикеток на стороне клиента. К сожалению комьюнити данного фреймворка еще не такое большое, что бы 
охватить весь спектр возникающих проблем при сборке приложения и разрешить все проблемы с сборкой окружения 
написанного на низкоуровневых С/C++(библиотеки компьютерного зрения, OCR). Учитывая мой небольшой опыт разработки на 
тот момент, было решено продолжить разработку на стеке Python/Django с фронтендом на React.js, а распознавание текстов 
осуществлять на сервере. В дальнейшем модуль распознавания текстов можно попробовать перенести на клиентскую сторону и 
серьезно разгрузить сервер, если все необходимые для OCR, Python библиотеки, локализованы и для JavaScript.

### Архитектура базы данных
В качестве базы данных проекта выбран PostgreSQL как наиболее полно отвечающем техническим требованиям проекта:
У каждого вещества может быть до сотни синонимов на одном только английском языке, так-же может быть несколько 
дублирующихся идентификаторов, и несколько классов опасности, что затрудняет использование классического реляционного 
подхода хранения данных, а масштабирование проекта до мультиязычного просто невозможно. Для этих целей использован 
формат JSONB и индексы GIN, что позволило хранить произвольное количество ключей и значений в 1 ячейке таблицы, 
но почти не теряя в скорости поиска по ключам и массивам JSONB, которая приближается к скорости чтения реляционных таблиц.
В будущем в к полям JSONB планируется создать индексы триграмм и использовать возможность неточного поиска по базе, 
что особенно актуально при поиске текста полученного OCR и содержащем ошибки.

### Data engeneering и сборка базы ингредиентов
В создании базы ингредиентов сервиса использовались:
* Substances Added to Food(U.S. Food and Drug Administration)
* COSING(European Commission) 
* EUCOSMETICS (NORMAN Suspect List Exchange)

Качество исходных данных не всегда соответствовало единому стандарту и содержало лишние символы, ошибки, поэтому 
данные предварительно обрабатывались Pandas/Regex. Некоторые данные (синонимы и идентификационные номера) 
извлекались с помощью парсинга [PubChem](https://pubchem.ncbi.nlm.nih.gov/) с использованием requests и BeautifulSoup 
и так-же проходили очистку. 
Для объединения данных из разных источников параллельно использовались несколько видов валидации по синонимам, 
идентификаторам и неточном соответствие(Python fuzzywuzzy lib) и в конечном итоге число ингредиентов используемых в пищевой и косметической промышленности было равно примерно 28000 шт.

### Сбор данных об опасности ингредиентов

Данные об опасности химических компонентов (GHS) извлекались из базы данных [Европейского химического 
агенства CLP](https://echa.europa.eu/information-on-chemicals/cl-inventory-database/)
 (~185000 компонетов) с помощью парсинга и использования многопоточности (Python multiprocessing). 
База CLP содержит различные ингредиенты и списки их классов опасности, а так-же количество организаций, которые заявили, 
что ингредиент имеет эти классы опасности. Данные в таблицах базе так-же имели отклонения от стандартного формата, 
поэтому приходилось писать сложные алгоритмы извлечения данных, их дальнейшей коррекции и агрегации перед добавлением 
в базу данных проекта. Данные из базы CLP так-же объединялись с уже собранной базой ингредиентов.
Задействованные технологии: requests, bs4, lxml(xpath), Pandas.

### Нормализация данных
Сырые данные об опасности ингредиентов были непригодны для показа пользователю и были нормализованы в нескольких 
реляционных таблицах. [Классификатор GHS](https://www.hsa.ie/eng/Publications_and_Forms/Publications/Chemical_and_Hazardous_Substances/CLP_Regulation_No_1272-2008_A4_Poster_I.pdf) представляет из себя классы опасности(напр раздражает кожу, канцероген) и 
категории опасности(баллы от 1 до 2,3 или 4 иногда с буквенными литерами), чем меньше цифра, тем более серьезный 
риск представляет ингредиент. Например Carc. 1A, означает канцерогенность 
уровня 1А. Безусловно такой классификатор был бы слишком сложен для того, что бы его показывать конечному пользователю, 
поэтому категории внутри каждого класса были нормализованы к 10-бальной системе 
(добавлено дополнительное поле в базу данных).
Задействованные технологии: psycopg2, Regex.

### Аггрегация
Модуль hazard_assessor в свою очередь осуществляет фильтрацию данных CLP с очень малым количеством уведомлений 
об опасности, которые скорее всего являются недостоверным. Например, если 1 из 100 компаний сообщила о том, что 
ингредиент является раздражителем глаз категории 2, то такие данные будут отсеняны. Очищенные данные проходят 
несколько аггрегаций и обобщений, что бы выдать рейтинг ингредиента и всего продукта.

### OCR
OpenTox использует для извлечения текстов с этикеток ранее разработанный [OCR модуль](https://github.com/a1xg/OCR-pipeline-for-product-labels)
Данный модуль извлекает не весь текст целиком, а с разбивкой на параграфы, это позволяет с большой долей вероятности определять язык внутри параграфа. Например для упаковок косметики поставляемых в Украину или Россию очень часто список ингредиентов пишется на английском, в то время как остальная часть упаковки написана на русском или украинском языках, таким образом для определения языка текста и реализации мультиязычного распознавания текста, необходимо сначала разбить его хотя бы на параграфы.
Распознанные параграфы текста проходят очистку в text_postprocessing.py и далее отправляются в базу данных, параграф текста с наибольшим количеством найденных в базе ингредиентов является составом продукта и используется дальше в модуле оценки рисков (hazard_assessor.py).
